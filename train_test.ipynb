{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from libsvm.svmutil import svm_problem, svm_parameter, svm_train, svm_save_model\n",
    "from discrete_wavelet_transform import dwt_2d\n",
    "from local_binary_pattern import lbp\n",
    "from feature_fusion import concatenate_lbp_dwt\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(directory):\n",
    "    # load preprocessed images\n",
    "    preprocessed_img = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        image = os.path.join(directory, filename)\n",
    "        if image is not None:\n",
    "            img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "            preprocessed_img.append(img)\n",
    "\n",
    "    # feature extraction\n",
    "    print(\"Performing Feature Extraction\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    # applying local binary pattern\n",
    "    print(\"Applying Local Binary Pattern\")\n",
    "    lbp_img_features = []\n",
    "    for i in preprocessed_img:\n",
    "        texture_features = lbp(i)\n",
    "        print('\\n\\n')\n",
    "        print(texture_features)\n",
    "\n",
    "\n",
    "        # store the features in a lbp_img_features list\n",
    "        lbp_img_features.append(texture_features)\n",
    "        print(f\"\\n{len(lbp_img_features)} out of {len(preprocessed_img)} images\\nPercentage: {(float(len(lbp_img_features)) / float(len(preprocessed_img)) * 100)}\\n\")\n",
    "    print('\\nLBP application finished\\n\\n')\n",
    "    \n",
    "    # applying discrete wavelet transform\n",
    "    print(\"Applying DWT to Images\")\n",
    "\n",
    "    dwt_img_features = []\n",
    "    for i in preprocessed_img:\n",
    "        freq_features = dwt_2d(i)\n",
    "        print('\\n\\n')\n",
    "        print(freq_features)\n",
    "\n",
    "        # store the features in a dwt_img_features list\n",
    "        dwt_img_features.append(cv2.resize(freq_features, dsize=(512, 512)))\n",
    "        print(f\"\\n{len(dwt_img_features)} out of {len(preprocessed_img)} images\\nPercentage: {(float(len(dwt_img_features)) / float(len(preprocessed_img)) * 100)}\\n\")\n",
    "    print(\"\\nDWT application finished\\n\\n\")\n",
    "\n",
    "\n",
    "    # applying feature fusion\n",
    "    fused_features = []\n",
    "\n",
    "    for dwt_features, lbp_features in zip(dwt_img_features, lbp_img_features):\n",
    "        feature_vector = concatenate_lbp_dwt(lbp_features, dwt_features)\n",
    "        fused_features.append(feature_vector)\n",
    "        print(f\"\\n{len(fused_features)} out of {len(preprocessed_img)} images\\nPercentage: {(float(len(fused_features)) / float(len(preprocessed_img)) * 100)}\\n\")\n",
    "\n",
    "\n",
    "    return fused_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(real, gan):\n",
    "    print(\"----------------------------Preparing the Data-------------------------------\\n\") \n",
    "    #label real  and gan datasets\n",
    "    real_label = np.ones((len(real), 1))\n",
    "    gan_label = np.zeros((len(gan), 1))\n",
    "\n",
    "\n",
    "    # combine the labels and datasets\n",
    "    dataset_labels = np.vstack((real_label, gan_label))\n",
    "    datasets = np.vstack((real, gan))\n",
    "\n",
    "    # reshape the labels and datasets for svm requirements\n",
    "    datasets_final = []\n",
    "\n",
    "    for i in datasets:\n",
    "        flattened_feature = i.flatten()\n",
    "        datasets_final.append(flattened_feature)\n",
    "    label_final = dataset_labels.reshape(dataset_labels.shape[0])\n",
    "\n",
    "    print(\"Labels: \", len(label_final))\n",
    "    print(\"Datasets: \", len(datasets_final))\n",
    "\n",
    "    return label_final, datasets_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(label, datasets):\n",
    "    print(\"----------------------Model Training--------------------------\\n\")\n",
    "    # SVM parameter\n",
    "    kernel_type = 2\n",
    "    C = 1.0\n",
    "\n",
    "    # check if length of datasets is equal to the length of labels\n",
    "    if len(label) == len(datasets):\n",
    "        prob = svm_problem(label, datasets)\n",
    "        validate = svm_parameter(f'-t {kernel_type} -c {C} -v 5')\n",
    "        param = svm_parameter(f'-t {kernel_type} -c {C}')\n",
    "        initial_accurary = svm_train(prob, validate)\n",
    "\n",
    "        model = svm_train(prob, param)\n",
    "    \n",
    "    else:\n",
    "        print(\"Length of datasets and labels do not match\\n\")  \n",
    "        print(\"Length of Datasets: \", len(datasets))\n",
    "        print(\"Length of Labels: \", len(label))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(real, gan):\n",
    "\n",
    "    mean1 = [np.mean(features) for features in real]\n",
    "    mean2 = [np.mean(features) for features in gan]\n",
    "\n",
    "    plt.plot(mean1, label=\"real\", color=\"blue\")\n",
    "    plt.plot(mean2, label=\"gan\", color=\"red\")\n",
    "\n",
    "    # Adding labels and a title\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Mean Value')\n",
    "    plt.title('Mean Values for Two Classes')\n",
    "\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide directory for preprocessed real and gan images\n",
    "real_directory = \"/Users/Danniel/Downloads/preprocessed_real\"\n",
    "gan_directory = \"/Users/Danniel/Downloads/preprocessed_gan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data preparation\n",
    "real_data = get_data(real_directory)\n",
    "gan_data = get_data(gan_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "visualize(real_data, gan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "labels, datasets = prepare_data(real_data, gan_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the data\n",
    "model = train_model(labels, datasets )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_file = \"/Users/Danniel/Downloads/faces_validate.model\"\n",
    "svm_save_model(model_file, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "from libsvm.svmutil import svm_load_model, svm_predict\n",
    "\n",
    "# test the model\n",
    "def predict(directory):\n",
    "    images = []\n",
    "\n",
    "    # load the images and store in images list\n",
    "    for filename in os.listdir(directory):\n",
    "        image = os.path.join(directory, filename)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "\n",
    "    print(len(images))        \n",
    "\n",
    "\n",
    "    # load the model\n",
    "    model_file = \"/Users/Danniel/Downloads/faces.model\"\n",
    "    loaded_model = svm_load_model(model_file)\n",
    "\n",
    "    # preprocessing\n",
    "    preprocessed_img = []\n",
    "    for i in images:\n",
    "        preprocessed_img.append(preprocessing(i))      \n",
    "\n",
    "\n",
    "    #  discrete wavelet transform\n",
    "    dwt_feature = []\n",
    "    print(\"\\n\\n-------------------DWT----------------------------\\n\")\n",
    "    for i in preprocessed_img:\n",
    "        dwt_feature.append(dwt_2d(i))\n",
    "        print(f\"\\n{len(dwt_feature)} out of {len(preprocessed_img)} images\\nPercentage: {(float(len(dwt_feature)) / float(len(preprocessed_img)) * 100)}\\n\")\n",
    "\n",
    "\n",
    "    # local binary pattern\n",
    "    lbp_feature = []\n",
    "    print(\"\\n\\n-------------------LBP----------------------------\\n\")\n",
    "    for i in preprocessed_img:\n",
    "        print(\"LBP Features:\\n\", lbp(i))\n",
    "        print(\"\\n\")\n",
    "        lbp_feature.append(lbp(i))\n",
    "        print(f\"\\n{len(lbp_feature)} out of {len(preprocessed_img)} images\\nPercentage: {(float(len(lbp_feature)) / float(len(preprocessed_img)) * 100)}\\n\")\n",
    "\n",
    "\n",
    "    # feature fusion\n",
    "    fused_vector = []\n",
    "    print(\"\\n\\n-------------------FEATURE FUSION----------------------------\\n\")\n",
    "    for frequency, texture in zip(dwt_feature, lbp_feature):\n",
    "        print(\"Fused Features:\\n\", concatenate_lbp_dwt(texture, frequency))\n",
    "        print(\"\\n\")\n",
    "        fused_vector.append(concatenate_lbp_dwt(texture, frequency))\n",
    "        print(f\"\\n{len(fused_vector)} out of {len(images)} images\\nPercentage: {(float(len(fused_vector)) / float(len(preprocessed_img)) * 100)}\\n\")\n",
    "\n",
    "    # flatten the feature vector\n",
    "    feature_vector = []\n",
    "    for i in fused_vector:\n",
    "        feature_vector.append(i.flatten())\n",
    "\n",
    "\n",
    "    # predict the result\n",
    "    print(\"\\n\\n-------------------THE MODEL IS PREDICTING----------------------------\\n\")\n",
    "    predicted_labels, _, _ = svm_predict([], feature_vector, loaded_model, '-q')\n",
    "\n",
    "\n",
    "    print(\"------------------------------------------RESULT-----------------------------------\\n\")\n",
    "    result = []\n",
    "    for i in predicted_labels:\n",
    "        if i == 1.0:\n",
    "            result.append(\"Real\")\n",
    "        elif i == 0.0:\n",
    "            result.append(\"GAN\")\n",
    "\n",
    "    print(result)\n",
    "\n",
    "#provide directory for testing dataset\n",
    "dir = \"\"\n",
    "\n",
    "predict(dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
