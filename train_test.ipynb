{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from liblinear.liblinearutil import save_model, load_model, train, predict\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Functions from train.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_data, spatial_frequency_feature_fusion, prepare_data, train_linear_model, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run this for preprocessing**\n",
    "\n",
    "- must include /utils\n",
    "- example path: \"/Users/Danniel/Detection-of-GAN-Generated-Images-using-Spatial-Frequency-Domain-Fusion-Data/utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# path of the folder \"Detection-of-GAN-Generated-Images-using-Spatial-Frequency-Domain-Fusion-Data\"\n",
    "sys.path.append(\"/Users/Danniel/Detection-of-GAN-Generated-Images-using-Spatial-Frequency-Domain-Fusion-Data/utils\")\n",
    "\n",
    "from preprocessing_save import load_image, save_image\n",
    "\n",
    "# directory for reading\n",
    "img_gan = \"/Users/Danniel/Downloads/Datasets/Datasets Scenes/Train/GAN\"\n",
    "img_real = \"/Users/Danniel/Downloads/Datasets/Datasets Scenes/Train/Real\"\n",
    "\n",
    "# directory for saving (must be an empty folder)\n",
    "save_dir_gan = \"/Users/Danniel/Downloads/Datasets/Datasets Scenes/Train/P_GAN\"\n",
    "save_dir_real = \"/Users/Danniel/Downloads/Datasets/Datasets Scenes/Train/P_Real\"\n",
    "\n",
    "# store the images\n",
    "image_real = load_image(img_real)\n",
    "image_gan = load_image(img_gan)\n",
    "\n",
    "save_image(image_real, save_dir_real)\n",
    "save_image(image_gan, save_dir_gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Provide directory for Preprocessed Real and GAN-Generated Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_directory = \"/Users/Danniel/Downloads/Datasets/Datasets Scenes/Train/P_GAN\"\n",
    "real_directory = \"/Users/Danniel/Downloads/Datasets/Datasets Scenes/Train/P_Real\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *\"get_data\" function will load the preprocessed images from the directory and store it in a list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data preparation\n",
    "gan_data = get_data(gan_directory)\n",
    "real_data = get_data(real_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Run to perform the proposed \"spatial frequency feature fusion\" method to extract meaningful features of an image to classify whether it is GAN-Generated or Real. The feature vector of each image will be stored in \"fused_features\" list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run feature extraction & feature fusion\n",
    "extracted_gan = spatial_frequency_feature_fusion(gan_data)\n",
    "extracted_real = spatial_frequency_feature_fusion(real_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For Data Visualization**\n",
    "- provide real and gan parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "visualize(extracted_gan, extracted_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation before feeding to the classifier**\n",
    "- assigning of labels\n",
    "- flattening of feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "labels, datasets = prepare_data(extracted_gan, extracted_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Store model data in hdf5 file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# provide directory for data folder\n",
    "os.chdir(\"/Users/Danniel/Downloads/File\")\n",
    "\n",
    "# rename the model data\n",
    "hf = h5py.File('data_faces_sample.h5', 'w')\n",
    "\n",
    "# store labels and datasets to the model data\n",
    "hf.create_dataset('labels', data=labels)\n",
    "hf.create_dataset('feature_vector',  data=datasets)\n",
    "\n",
    "# close the h5py\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load hdf5 model data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory of data folder\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/Danniel/Downloads/File\")\n",
    "\n",
    "# provide filename of the model data\n",
    "rf = h5py.File('data.h5', 'r')\n",
    "\n",
    "rf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_labels = rf.get('labels')\n",
    "loaded_feature_vector = rf.get('feature_vector')\n",
    "\n",
    "# convert object to numpy array\n",
    "np_labels = np.array(loaded_labels)\n",
    "np_features = np.array(loaded_feature_vector)\n",
    "\n",
    "print(\"Loaded Labels: \",len(np_labels))\n",
    "print(\"Loaded Features: \", len(np_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**\n",
    "- Liblinear\n",
    "\n",
    "\n",
    "***\n",
    "    - change the parameter if the data are from loaded file\n",
    "    - train_model(np_labels, np_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the data\n",
    "# model = train_linear_model(labels, datasets, C=1)\n",
    "\n",
    "\n",
    "model = train(np_labels, np_features, f'-s 1 -c 1 -B 1 -w1 10.0 -v 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save the model using \".model\" extension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_file = \"/Users/Danniel/Downloads/Model/True Model/scenes.model\"\n",
    "save_model(model_file, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = load_model(\"/Users/Danniel/Downloads/Model/True Model/faces_new.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Platt Scaling**\n",
    "- run this to provide the platt scaling of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, scores = predict(labels, datasets, model_file)\n",
    "\n",
    "validate = train(labels, scores, '-s 0 -c 1 -B 1 -v 5')\n",
    "platt_scale = train(labels, scores, '-s 0 -c 1 -B 1')\n",
    "\n",
    "save_model('/Users/Danniel/Downloads/Model/True Platt Scaling/platt_scale_scenes.model', platt_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Testing**\n",
    "- provide directory (folder) for testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Testing Combined GAN and Real Images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "from train import spatial_frequency_feature_fusion\n",
    "\n",
    "# load platt scaler\n",
    "plat_file = load_model(\"platt scaler/platt_scale_faces.model\")\n",
    "\n",
    "# test the model\n",
    "def get_test_data(directory):\n",
    "    images = []\n",
    "\n",
    "    # load the images and store in images list\n",
    "    for filename in os.listdir(directory):\n",
    "        image = os.path.join(directory, filename)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "\n",
    "    # preprocessing\n",
    "    preprocessed_img = []\n",
    "    for i in images:\n",
    "        preprocessed_img.append(preprocessing(i))   \n",
    "\n",
    "    # flatten the feature vector\n",
    "    fused_features = spatial_frequency_feature_fusion(preprocessed_img)\n",
    "    labels = np.ones((len(fused_features), 1)) \n",
    "    true_label = labels.reshape(labels.shape[0])\n",
    "\n",
    "    feature_vector = []\n",
    "    for i in fused_features:\n",
    "        print(i)\n",
    "        feature_vector.append(i.flatten())\n",
    "\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def prepare_test_data(gan, real):\n",
    "    print(\"\\n\\n-------------------PREPARING TEST DATA----------------------------\\n\")\n",
    "    #label real  and gan datasets\n",
    "    gan_label = np.ones((len(gan), 1))\n",
    "    real_label = np.zeros((len(real), 1))\n",
    "\n",
    "    # combine the labels and datasets\n",
    "    dataset_labels = np.vstack((gan_label, real_label))\n",
    "    datasets = np.vstack((gan, real))\n",
    "\n",
    "    feature_vector = [i.flatten() for i in datasets]\n",
    "    \n",
    "    true_label = dataset_labels.reshape(dataset_labels.shape[0])\n",
    "\n",
    "    return feature_vector, true_label\n",
    "\n",
    "\n",
    "def predict_labels(feature_vector, true_label, model):  \n",
    "    # predict the result\n",
    "    print(\"\\n\\n-------------------THE MODEL IS PREDICTING----------------------------\\n\")\n",
    "    _, _, svm_scores= predict(true_label, feature_vector, model)\n",
    "    predicted_labels, _, probability_estimates = predict(labels, svm_scores, plat_file, '-b 1')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"------------------------------------------RESULT-----------------------------------\\n\")\n",
    "    result = []\n",
    "    for i in predicted_labels:\n",
    "        if i == 1.0:\n",
    "            result.append(\"GAN\")\n",
    "        elif i == 0.0:\n",
    "            result.append(\"Real\")\n",
    "\n",
    "    \n",
    "    print(result)\n",
    "    print(probability_estimates)\n",
    "\n",
    "\n",
    "    return svm_scores, predicted_labels\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    option = input(\"Does your data came from text file? (y/n)\")\n",
    "\n",
    "    if option.lower() == \"y\":\n",
    "        # mode prediction\n",
    "        scores = predict_labels(np_features, np_labels, model_file)\n",
    "        break\n",
    "\n",
    "    elif option.lower() == \"n\":           \n",
    "        #provide directory for testing dataset\n",
    "        dir_gan = \"/Users/Danniel/Downloads/Datasets/Datasets Faces/Test/GAN\"\n",
    "        dir_real = \"/Users/Danniel/Downloads/Datasets/Datasets Faces/Test/Real\"\n",
    "\n",
    "        # undergo spatial-frequency-feature fusion\n",
    "        gan = get_test_data(dir_gan)\n",
    "        real = get_test_data(dir_real)\n",
    "\n",
    "        # combine the real and gan data\n",
    "        features, labels = prepare_test_data(gan, real)\n",
    "\n",
    "        # model prediction\n",
    "        scores, predicted_labels = predict_labels(features, labels, model_file)\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "dir = \"/Users/Danniel/Downloads/Datasets/Datasets Animals/Test/Real\"\n",
    "\n",
    "filename = os.listdir(dir)\n",
    "\n",
    "with open('datasets.csv', 'a', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # csv_writer.writerow(['Filename', 'True Labels'])\n",
    "\n",
    "    for file in filename:\n",
    "        csv_writer.writerow([file, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮▮ |  100.00%\r"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "dir = \"/Users/Danniel/Downloads/Pixelated/GAN\"\n",
    "\n",
    "if os.path.isdir(dir):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(dir)\n",
    "\n",
    "def pixelate(image, i):\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image)\n",
    "\n",
    "    pixelated_image = cv2.resize(image, dsize=(64, 64))\n",
    "    cv2.imwrite(f\"/Users/Danniel/Downloads/Pixelated/GAN/pixelated_gan({i}).png\", pixelated_image)\n",
    "\n",
    "def progress_bar(progress, total):\n",
    "    percent = 100 * (progress / float(total))\n",
    "    bar = '▮' * int(percent) + '-' * (100 - int(percent))\n",
    "    print(f\"\\r|{bar} | {percent: .2f}%\", end=\"\\r\")    \n",
    "\n",
    "\n",
    "# load preprocessed images\n",
    "directory = \"/Users/Danniel/Downloads/combined class test gan\"\n",
    "img = []\n",
    "for filename in os.listdir(directory):\n",
    "    image = os.path.join(directory, filename)\n",
    "    if image is not None:\n",
    "        img.append(image)   \n",
    "\n",
    "for index, image in enumerate(img):\n",
    "    pixelate(image, index)\n",
    "    progress_bar(index + 1, len(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
