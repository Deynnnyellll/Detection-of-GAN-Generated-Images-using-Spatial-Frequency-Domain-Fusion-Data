{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from libsvm.svmutil import svm_save_model, svm_load_model, svm_predict\n",
    "from liblinear.liblinearutil import save_model, load_model, predict\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Functions from train.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_data, spatial_frequency_feature_fusion, prepare_data, train_model, train_linear_model, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run this for preprocessing**\n",
    "\n",
    "- must include /utils\n",
    "- example path: \"/Users/Danniel/Detection-of-GAN-Generated-Images-using-Spatial-Frequency-Domain-Fusion-Data/utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# path of the folder \"Detection-of-GAN-Generated-Images-using-Spatial-Frequency-Domain-Fusion-Data\"\n",
    "sys.path.append(\"/Users/Danniel/Detection-of-GAN-Generated-Images-using-Spatial-Frequency-Domain-Fusion-Data/utils\")\n",
    "\n",
    "from preprocessing_save import load_image, save_image\n",
    "\n",
    "# directory for reading\n",
    "img_real = \"/Users/Danniel/Downloads/Datasets/Low Dataset/real\"\n",
    "img_gan = \"/Users/Danniel/Downloads/Datasets/Low Dataset/gan\"\n",
    "\n",
    "# directory for saving (must be an empty folder)\n",
    "save_dir_real = \"/Users/Danniel/Downloads/Datasets/Low Dataset/p_real\"\n",
    "save_dir_gan = \"/Users/Danniel/Downloads/Datasets/Low Dataset/p_gan\"\n",
    "\n",
    "# store the images\n",
    "image_real = load_image(img_real)\n",
    "image_gan = load_image(img_gan)\n",
    "\n",
    "save_image(image_real, save_dir_real)\n",
    "save_image(image_gan, save_dir_gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Provide directory for Preprocessed Real and GAN-Generated Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_directory = \"/Users/Danniel/Downloads/Datasets/Low Dataset/p_real\"\n",
    "gan_directory = \"/Users/Danniel/Downloads/Datasets/Low Dataset/p_gan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *\"get_data\" function will load the preprocessed images from the directory and store it in a list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run data preparation\n",
    "real_data = get_data(real_directory)\n",
    "gan_data = get_data(gan_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Run to perform the proposed \"spatial frequency feature fusion\" method to extract meaningful features of an image to classify whether it is GAN-Generated or Real. The feature vector of each image will be stored in \"fused_features\" list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run feature extraction & feature fusion\n",
    "extracted_real = spatial_frequency_feature_fusion(real_data)\n",
    "extracted_gan = spatial_frequency_feature_fusion(gan_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For Data Visualization**\n",
    "- provide real and gan parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "visualize(extracted_real, extracted_gan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preparation before feeding to the classifier**\n",
    "- assigning of labels\n",
    "- flattening of feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "labels, datasets = prepare_data(extracted_real, extracted_gan)\n",
    "print(labels, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run this cell if you want to store the data in txt**\n",
    "- it can be useful for storing training data to avoid repetition of process\n",
    "\n",
    "**Suggested format**\n",
    "- train_labels.txt\n",
    "- train_features.txt\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.savetxt(\"/Users/User/Desktop/txtfiles/train_labels.txt\", labels)\n",
    "np.savetxt(\"/Users/User/Desktop/txtfiles/train_features.txt\", datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "loaded_labels = np.loadtxt(\"/Users/User/Desktop/txtfiles/train_labels.txt\")\n",
    "loaded_features = np.loadtxt(\"/Users/User/Desktop/txtfiles/train_features.txt\")\n",
    "\n",
    "print(\"Labels: \", len(loaded_labels))\n",
    "print(\"Features: \", len(loaded_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**\n",
    "- LibSVM\n",
    "- Support Vector Machine\n",
    "- Linear Kernel\n",
    "\n",
    "\n",
    "***\n",
    "    - change the parameter if the data are from loaded text file\n",
    "    - train_model(loaded_labels, loaded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the data\n",
    "model = train_model(labels, datasets, C=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**\n",
    "- Liblinear\n",
    "\n",
    "\n",
    "***\n",
    "    - change the parameter if the data are from loaded text file\n",
    "    - train_model(loaded_labels, loaded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the data\n",
    "model = train_model(labels, datasets, C=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Save the model using \".model\" extension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_file = \"/Users/User/Desktop/model/updatedobjects_new.model\"\n",
    "svm_save_model(model_file, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load the model***\n",
    "- use \"load_model\" if model is trained in liblinear\n",
    "- use \"svm_load_model\" if model is trained in libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = svm_load_model(\"/Users/User/Desktop/model/updatedobjects_new.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Testing**\n",
    "- provide directory (folder) for testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Testing Combined GAN and Real Images*\n",
    "- use \"predict\" if model is trained in liblinear\n",
    "- use \"svm_predict\" if model is trained in libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "from train import spatial_frequency_feature_fusion\n",
    "\n",
    "# test the model\n",
    "def get_test_data(directory):\n",
    "    images = []\n",
    "\n",
    "    # load the images and store in images list\n",
    "    for filename in os.listdir(directory):\n",
    "        image = os.path.join(directory, filename)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "\n",
    "    # preprocessing\n",
    "    preprocessed_img = []\n",
    "    for i in images:\n",
    "        preprocessed_img.append(preprocessing(i))   \n",
    "\n",
    "    # flatten the feature vector\n",
    "    fused_features = spatial_frequency_feature_fusion(preprocessed_img)\n",
    "    labels = np.ones((len(fused_features), 1)) \n",
    "    true_label = labels.reshape(labels.shape[0])\n",
    "\n",
    "    feature_vector = []\n",
    "    for i in fused_features:\n",
    "        print(i)\n",
    "        feature_vector.append(i.flatten())\n",
    "\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def prepare_test_data(real, gan):\n",
    "    print(\"\\n\\n-------------------PREPARING TEST DATA----------------------------\\n\")\n",
    "    #label real  and gan datasets\n",
    "    real_label = np.ones((len(real), 1))\n",
    "    gan_label = np.zeros((len(gan), 1))\n",
    "\n",
    "    # combine the labels and datasets\n",
    "    dataset_labels = np.vstack((real_label, gan_label))\n",
    "    datasets = np.vstack((real, gan))\n",
    "\n",
    "    feature_vector = [i.flatten() for i in datasets]\n",
    "    true_label = dataset_labels.reshape(dataset_labels.shape[0])\n",
    "\n",
    "    return feature_vector, true_label\n",
    "\n",
    "\n",
    "def predict(feature_vector, true_label, model):  \n",
    "    # predict the result\n",
    "    print(\"\\n\\n-------------------THE MODEL IS PREDICTING----------------------------\\n\")\n",
    "    predicted_labels, _, likelihood = svm_predict(true_label, feature_vector, model, '-b 1')\n",
    "\n",
    "\n",
    "    print(\"------------------------------------------RESULT-----------------------------------\\n\")\n",
    "    result = []\n",
    "    for i in predicted_labels:\n",
    "        if i == 1.0:\n",
    "            result.append(\"Real\")\n",
    "        elif i == 0.0:\n",
    "            result.append(\"GAN\")\n",
    "\n",
    "    \n",
    "    print(predicted_labels)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    option = input(\"Does your data came from text file? (y/n)\")\n",
    "\n",
    "    if option.lower() == \"y\":\n",
    "        # mode prediction\n",
    "        predict(loaded_features, loaded_labels, model_file)\n",
    "        break\n",
    "\n",
    "    elif option.lower() == \"n\":           \n",
    "        #provide directory for testing dataset\n",
    "        dir_real = \"/Users/User/Desktop/real test/real test objects\"\n",
    "        dir_gan = \"/Users/User/Desktop/gan test/gan test objects\"\n",
    "\n",
    "        # undergo spatial-frequency-feature fusion\n",
    "        real = get_test_data(dir_real)\n",
    "        gan = get_test_data(dir_gan)\n",
    "\n",
    "        # combine the real and gan data\n",
    "        features, labels = prepare_test_data(real, gan)\n",
    "\n",
    "        # model prediction\n",
    "        predict(features, labels, model_file)\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid Input\")\n",
    "\n",
    "###########################################################################################################################################\n",
    "# existing_model_file = \"/Users/Danniel/Downloads/sample.model\"\n",
    "# existing_model = svm_load_model(existing_model_file)\n",
    "\n",
    "# # New data\n",
    "# new_labels = np.array(new_labels)\n",
    "# new_datasets = np.array(new_datasets)\n",
    "\n",
    "# # Train or update the model incrementally\n",
    "# updated_model = train_model(existing_model, new_labels, new_datasets)\n",
    "\n",
    "# # Save the updated model\n",
    "# model_file = \"/Users/Danniel/Downloads/updated_model.model\"\n",
    "# svm_save_model(model_file, updated_model)\n",
    "\n",
    "# # Use the updated model for prediction\n",
    "# image_directory = \"/Users/Danniel/Downloads/Low Dataset/test\"\n",
    "# images = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory)]\n",
    "# predict(updated_model, images)\n",
    "########################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Testing One Class of Image only*\n",
    "- use \"predict\" if model is trained in liblinear\n",
    "- use \"svm_predict\" if model is trained in libsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "from train import spatial_frequency_feature_fusion\n",
    "\n",
    "# test the model\n",
    "def get_test_data(directory):\n",
    "    images = []\n",
    "\n",
    "    # load the images and store in images list\n",
    "    for filename in os.listdir(directory):\n",
    "        image = os.path.join(directory, filename)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "\n",
    "    # preprocessing\n",
    "    preprocessed_img = []\n",
    "    for i in images:\n",
    "        preprocessed_img.append(preprocessing(i))   \n",
    "\n",
    "    # flatten the feature vector\n",
    "    fused_features = spatial_frequency_feature_fusion(preprocessed_img)\n",
    "    labels = np.ones((len(fused_features), 1)) \n",
    "    true_label = labels.reshape(labels.shape[0])\n",
    "\n",
    "    feature_vector = []\n",
    "    for i in fused_features:\n",
    "        print(i)\n",
    "        feature_vector.append(i.flatten())\n",
    "\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def prepare_test_data(gan):\n",
    "    print(\"\\n\\n-------------------PREPARING TEST DATA----------------------------\\n\")\n",
    "    #label real  and gan datasets\n",
    "    #real_label = np.ones((len(real), 1))\n",
    "    gan_label = np.zeros((len(gan), 1))\n",
    "\n",
    "    # combine the labels and datasets\n",
    "    #dataset_labels = np.vstack((real_label, gan_label))\n",
    "    #datasets = np.vstack((real, gan))\n",
    "\n",
    "    feature_vector = [i.flatten() for i in gan]\n",
    "    true_label = gan_label.reshape(gan_label.shape[0])\n",
    "\n",
    "    return feature_vector, true_label\n",
    "\n",
    "\n",
    "def predict(feature_vector, true_label, model):  \n",
    "    # predict the result\n",
    "    print(\"\\n\\n-------------------THE MODEL IS PREDICTING----------------------------\\n\")\n",
    "    predicted_labels, _, likelihood = svm_predict(true_label, feature_vector, model, '-b 1')\n",
    "\n",
    "\n",
    "    print(\"------------------------------------------RESULT-----------------------------------\\n\")\n",
    "    result = []\n",
    "    for i in predicted_labels:\n",
    "        if i == 1.0:\n",
    "            result.append(\"Real\")\n",
    "        elif i == 0.0:\n",
    "            result.append(\"GAN\")\n",
    "\n",
    "    \n",
    "    print(predicted_labels)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    option = input(\"Does your data came from text file? (y/n)\")\n",
    "\n",
    "    if option.lower() == \"y\":\n",
    "        # mode prediction\n",
    "        predict(loaded_features, loaded_labels, model_file)\n",
    "        break\n",
    "\n",
    "    elif option.lower() == \"n\":           \n",
    "        #provide directory for testing dataset\n",
    "        #dir_real = \"/Users/User/Desktop/real test/real test objects\"\n",
    "        dir_gan = \"/Users/User/Desktop/gan test/gan test objects\"\n",
    "\n",
    "        # undergo spatial-frequency-feature fusion\n",
    "        #real = get_test_data(dir_real)\n",
    "        gan = get_test_data(dir_gan)\n",
    "\n",
    "        # combine the real and gan data\n",
    "        features, labels = prepare_test_data(gan)\n",
    "\n",
    "        # model prediction\n",
    "        predict(features, labels, model_file)\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid Input\")\n",
    "\n",
    "###########################################################################################################################################\n",
    "# existing_model_file = \"/Users/Danniel/Downloads/sample.model\"\n",
    "# existing_model = svm_load_model(existing_model_file)\n",
    "\n",
    "# # New data\n",
    "# new_labels = np.array(new_labels)\n",
    "# new_datasets = np.array(new_datasets)\n",
    "\n",
    "# # Train or update the model incrementally\n",
    "# updated_model = train_model(existing_model, new_labels, new_datasets)\n",
    "\n",
    "# # Save the updated model\n",
    "# model_file = \"/Users/Danniel/Downloads/updated_model.model\"\n",
    "# svm_save_model(model_file, updated_model)\n",
    "\n",
    "# # Use the updated model for prediction\n",
    "# image_directory = \"/Users/Danniel/Downloads/Low Dataset/test\"\n",
    "# images = [os.path.join(image_directory, filename) for filename in os.listdir(image_directory)]\n",
    "# predict(updated_model, images)\n",
    "########################################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Store the test data in txt file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "np.savetxt(\"/Users/User/Desktop/txtfiles/test_labels.txt\", labels)\n",
    "np.savetxt(\"/Users/User/Desktop/txtfiles/test_features.txt\", features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
